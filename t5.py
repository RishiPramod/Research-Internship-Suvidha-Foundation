# -*- coding: utf-8 -*-
"""T5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12UCS5yCA0g556GKi7A7ZioTxcP3PYKnp
"""

!pip install transformers[sentencepiece] torch datasets evaluate rouge_score

import pandas as pd
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import evaluate
from datasets import Dataset

try:
    df = pd.read_csv("/content/drive/MyDrive/The_Hindu_paper_dataset_2015_to_2025.csv")
    print("Dataset loaded successfully!")
    print(df.head())
except FileNotFoundError:
    print("Error: The CSV file was not found. Please upload 'The_Hindu_paper_dataset_2015_to_2025.csv' to your Colab session.")
    exit()

df.dropna(subset=['Content', 'Headline'], inplace=True)
df.reset_index(drop=True, inplace=True)

df_sample = df.sample(n=100, random_state=42).copy()

model_name = "t5-small"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

def generate_summary(text):
    # Prepend the summarization task prefix
    inputs = tokenizer(
        "summarize: " + text,
        return_tensors="pt",
        max_length=512,
        truncation=True
    )

    # Generate the summary
    outputs = model.generate(
        inputs["input_ids"],
        max_length=150,
        min_length=40,
        length_penalty=2.0,
        num_beams=4,
        early_stopping=True
    )

    # Decode the generated output to a string
    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return summary

generated_summaries = [generate_summary(content) for content in df_sample['Content']]

predictions = generated_summaries
references = df_sample['Headline'].tolist()

rouge_metric = evaluate.load("rouge")

rouge_scores = rouge_metric.compute(
    predictions=predictions,
    references=references,
    rouge_types=["rouge1", "rouge2", "rougeL"]
)

print("\n--- ROUGE Scores ---")
print("ROUGE-1 Score (F-measure):", round(rouge_scores['rouge1'], 4))
print("ROUGE-2 Score (F-measure):", round(rouge_scores['rouge2'], 4))
print("ROUGE-L Score (F-measure):", round(rouge_scores['rougeL'], 4))

print("\nFinal ROUGE Scores:")
print(f"ROUGE-1: {rouge_scores['rouge1']:.2f}")
print(f"ROUGE-2: {rouge_scores['rouge2']:.2f}")
print(f"ROUGE-L: {rouge_scores['rougeL']:.2f}")

